from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import time
import os

app = FastAPI(
    title="Sarcasm Detection API",
    description="API –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–∞—Ä–∫–∞–∑–º–∞ –≤ —Ç–µ–∫—Å—Ç–∞—Ö —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º BERT-Tiny",
    version="2.0.0"
)


class BERTPredictor:
    def __init__(self):
        self.model_name = "cointegrated/rubert-tiny2"
        print("‚ö° –ó–∞–≥—Ä—É–∑–∫–∞ BERT-Tiny –º–æ–¥–µ–ª–∏...")

        try:
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForSequenceClassification.from_pretrained(
                self.model_name,
                num_labels=2
            )
            self.model.eval()  # –†–µ–∂–∏–º inference
            print("‚úÖ BERT-Tiny –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise e

    def predict(self, text: str):
        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            truncation=True,
            padding=True,
            max_length=512
        )

        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        with torch.no_grad():
            outputs = self.model(**inputs)
            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)

        # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        prob_not_sarcastic = predictions[0][0].item()
        prob_sarcastic = predictions[0][1].item()

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å
        is_sarcastic = prob_sarcastic > prob_not_sarcastic
        probability = prob_sarcastic if is_sarcastic else prob_not_sarcastic
        class_id = 1 if is_sarcastic else 0

        return {
            "is_sarcastic": is_sarcastic,
            "probability": probability,
            "class_id": class_id,
            "probabilities": {
                "not_sarcastic": prob_not_sarcastic,
                "sarcastic": prob_sarcastic
            }
        }


# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
try:
    predictor = BERTPredictor()
    print("üéØ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
except Exception as e:
    print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏: {e}")
    predictor = None


class TextRequest(BaseModel):
    text: str


class PredictionResponse(BaseModel):
    text: str
    class_name: str
    class_id: int
    probability: float
    confidence: str
    processing_time: float
    model: str


@app.get("/")
async def root():
    return {
        "message": "Sarcasm Detection API with BERT-Tiny",
        "version": "2.0.0",
        "model": "rubert-tiny2",
        "endpoints": {
            "docs": "/docs",
            "health": "/health",
            "predict": "/predict"
        }
    }


@app.get("/health")
async def health_check():
    return {
        "status": "healthy" if predictor else "unhealthy",
        "timestamp": time.time(),
        "model_loaded": predictor is not None,
        "model_name": "cointegrated/rubert-tiny2"
    }


@app.post("/predict", response_model=PredictionResponse)
async def predict_sarcasm(request: TextRequest):
    start_time = time.time()

    if predictor is None:
        raise HTTPException(status_code=503, detail="–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")

    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç BERT
        result = predictor.predict(request.text)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        probability = result["probability"]
        if probability > 0.8:
            confidence = "high"
        elif probability > 0.6:
            confidence = "medium"
        else:
            confidence = "low"

        processing_time = time.time() - start_time

        return PredictionResponse(
            text=request.text,
            class_name="Sarcasm" if result["is_sarcastic"] else "Not Sarcasm",
            class_id=result["class_id"],
            probability=probability,
            confidence=confidence,
            processing_time=processing_time,
            model="BERT-Tiny"
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {str(e)}")


@app.get("/model-info")
async def model_info():
    return {
        "model_type": "BERT-Tiny (Transformers)",
        "model_name": "cointegrated/rubert-tiny2",
        "classes": ["Not Sarcasm", "Sarcasm"],
        "max_length": 512,
        "framework": "PyTorch + Transformers"
    }


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8000)
    